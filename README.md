# CV_HW

Логи, профилировку и confusion matrix можно скачать по ссылке: https://disk.360.yandex.ru/d/jSpaf40wI6HFeA

## Запуск

1. Скачайте .ipynb файл и откройте его в Google colab. (или откройте этот же файл напрямую по ссылке: https://colab.research.google.com/drive/19tyHf7UsphEVO_IAjE76QlkEBtm0tN8m?usp=sharing)
2. Выставите Runtime -> Change Runtime Type -> T4 GPU перед запуском
3. Запускайте ячейки по очереди до конца

## Описание Эксперимента

Этот репозиторий содержит полностью готовый к запуску в Google Colab эксперимент по сравнению простой CNN и линейного классификатора (linear probe) поверх предобученного ViT-Tiny. Включены: подготовка данных, sanity-check (оверфит нескольких батчей), логирование в TensorBoard, профилировка torch.profiler, расчёт метрик (accuracy, macro-F1), построение матриц ошибок и сохранение чекпоинтов/отчёта.

### Данные

Автосборка мини-датасета из CIFAR-10
Выбираются ≥5 классов, фиксируется количество изображений на класс, и всё сохраняется в структуре ImageFolder.

Аугментации:
- train: RandomResizedCrop(224, scale=(0.8,1.0)), RandomHorizontalFlip, нормализация под ImageNet.

- val: Resize(256) → CenterCrop(224), нормализация под ImageNet.


### Архитектуры
1. Простая CNN
  3 свёрточных блока с Conv2d + BatchNorm2d + ReLU + MaxPool2d, затем AdaptiveAvgPool2d → Linear классификатор. Размер входа — 224×224.

2. ViT-Tiny (linear probe)
  Модель vit_tiny_patch16_224 из timm с предобученными весами:
  - Заморожен весь бэкон (включая режим eval()).
  - Обучается только линейная голова (head.train()).

### Обучение

В тетрадке реализован общий цикл обучения:
- AdamW, AMP (autocast + GradScaler), Cosine LR со стадийным warmup.
- Логирование в TensorBoard: train/val loss, accuracy, macro-F1, LR.
- Гистограммы весов и градиентов.
- Sanity-check: отдельный прогон для оверфита на 1–2 батчах — должен быстро достигать acc ≈ 1.0.

### Профилировка

Используется torch.profiler с расписанием wait 5 / warmup 5 / active 50–100 шагов. Трейс сохраняется в подкаталог TensorBoard-логов (.../profiler) и просматривается в TensorBoard → Profile.

### Оценка и визуализация

- Метрики на val: accuracy, macro-F1.
- Classification report по классам.
- Confusion matrix в двух видах: абсолютные значения и нормированная по строкам. PNG-файлы сохраняются в runs/....

Также сохраняются чекпоинты:

- checkpoints/cnn_best.pt
- checkpoints/vit_tiny_linear_probe.pt

И JSON-отчёт-шаблон:
- runs/.../final_report.json с полями: пути к логам/чекпоинтам, список классов, заметки и итоговые выводы.


## Выводы

- ViT-Tiny быстро достигает высокой top-1 точности, но при изначальном LR (5e-3) и агрессивных аугментациях мы наблюдали нестабильный валид. лосс и провал по macro-F1 (модель переобучается на 1–2 класса). Причина колебаний — сетап, а не архитектура. После снижения BASE_LR_VIT (до 1e-3), лосс становится монотоннее, а macro-F1 подтягивается за счёт более ровных границ между классами.
- CNN сходится плавнее и предсказуемее, особенно на sanity-subset (оверфит за 30-40 эпох на 1 батче). На полном трейн-сете CNN обычно даёт чуть меньшую или сопоставимую точность (accuracy ~0.6), но более ровный macro-F1 из коробки (меньше перекоса в 1–2 класса), т.к. чувствительнее к локальным текстурам при сильном апскейле CIFAR-картинок до 224×224.
- Матрица ошибок выявляет систематические путаницы между визуально похожими классами (например, «автомобиль/самолёт» при агрессивном кропе), а у линейного проба — тенденцию «складывать» редкие классы в один доминирующий.

**Итог**: на датасете ViT-Tiny с корректно настроенным linear probe превосходит простую CNN по точности и, после стабилизации обучения, по macro-F1, оставаясь **незначительно** дороже по времени/итерации. CNN — сильная базовая линия: проще и дешевле. Для задач с ограниченными ресурсами или сильным апскейлом изображений CNN может быть предпочтительнее; при возможности — linear probe на ViT даёт лучший потолок качества.
